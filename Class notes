# Notes from 2.12.2021:

we don't use the quantile $F^{-1}$ because to compute for the tail of the distribution is not good 

peaks-over-threshold we take values high enough to show the extremes -> number of exceedences arise according to a Poisson distribution with lambda parameter (probability of getting an exceedence)

to find mu we can use the plot method not perfect answer though we take the quantile and keep what is over the quantile 
alpha is the risk level that we want to take 

ES: expected shortfall

practical 2: back testing

data -> $x_1, .., x_n$ -> cross validation for the risk measure -> split data set in two (training set and test set) -> backtesting on training test -> use a window on 150 days for the value at risk everyday -> estimation of ? value at risk -> every day for each value at risk at level alpha there is a probaility p = 1-p that my value at risk is exceeded -> value at risk has a very small probability 1 - alpha that it is exceeded -> distribution is 0 (not violated) or 1 (if violated) is the bernouilli distribution : if x > value at risk at value alpha, = 1 with prob p = 1- alpha and = 0 otherwise with p = alpha -> everyday we have an indicator that follows a bernouilli distribution if the model/value at risk is correct -> if 500 value at risk every day for 500 days: the sum of independent bernouillis is a binomial distirbution (repeats independent bernuoilli experiments) where n= 500 and p = 0.5 -> intuitively: 500 days for each day we have a value at risk at alpha 0.95% -> how many times can i expect a value to be over the value at risk: 500*0.05 = 25 times -> we can expect that in 25 times we have a vioation of the value at risk = value that canbe exceeded once time in probability 0.05 (n is n' in the slides ) => on R: estimate value at risk every day with moving window of historical data, each day we compare with the data we have (crossvalidation), if validated = 1 otherwise 0, binomial test => compare the expected number of violation with the ones we got => best way to assess the value at risk 

the normal distribution would ten dto underestmate the value at risk/risk we we'd compare our value at risk with the quantile of the normal distribution !

Module 5: multivariate risk

It matters because the risks happen together (risks are dependent)

We can see an eliptical behavior of the joint distribution of for example return. There can be upper tail dependence (linear correlation on the top left of the plot = upper quadrant => upper tail dependence)

Joint df: distribution of the random vector 

Multivariate models: marginal distrbution -> consider the dependence of the risk, if independence then the joint distribution is = the product of the two probabilities -> densities: joint densities -> if independence look at the formula of the distributions 

Multivariate normal distribution -> check formula in the slide

Bivariate normal data: look at the shape on the slides (if correaltion = 0 -> no correlation so independence, if < 0 negative dependence, if > 0 dependence) : what does the bulk of the distribution looks like ? 

motivation for looking at the extremes that happen jointly: see the slide 

extremes for 2 variables: at least x1 or x2 are extremes or both -> means it is under an extreme situation -> extreme value theory: define a coefficient that measures how much dependence/data we have in the top righ of the data plotted = upper quadrant -> upper tial coefficient: packages in R estimate it for us or we can do it ourselves using one of the formulas from the slides -> if coeff is close to 1 it means that the tail is 0 

no dependence in the bulk of the distribution but dependence in the tail -> tail dependence or extremal dependence: when we go far in the tail, what is the proba that y if above the threshold considering that x is already past the threshold = proba that y is in the upper quadrant (upper tail dependence)

tail dependence: if extreme for x1 (low rank) not extreme for x2 (high rank) and vice versa and lambdy_mu is 0

Module 6: measure the tail dependence = how dependent are for example the two log returns ? 

testing for multivariate normality: R provide a function for this to asses if the multivariate normal distribution is adequate to our data -> does it fit well supposing that the two margins are normal -> use a qqplot or a Jarque Bera test -> for the joint normality we can sue the it is chi-squared sitrbibuted using a qqplot  or a test

important becasue if we fit bivariate normal distribution when it should not be used, we would see that the level of tails wont fit well-> it would fit well for the body of the data but not the tail 

S shape of the qqplot shows that the normal distribution works well for the bulk of the data but not the tail -> the S shape is the departure from the normality

calculating risk: interest about the tail of the distribution -> consider the tail dependence 

multivariate t distribution: bit better because heavy tail distribution -> when there is a covariance matrice sigma it means that it is an eliptical distrbution because the elipse depends on the covariance matrix -> compare elipse with true distribution of the data to check which distribution fits well the data 


















